{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial walks you through using the HaloAnalysis package to read and use halo catalogs generated by Rockstar and merger trees generated via ConsistentTrees, from Gizmo simulations.\n",
    "\n",
    "@author: Andrew Wetzel <arwetzel@gmail.com>\n",
    "\n",
    "First, move within a simulation directory that contains a sub-directory 'halo/' that in turn contains a directory named rockstar/ or rockstar_dm/. (By convention, rockstar/ implies that Rockstar halo finding ran using all particle species, dark matter + stars + gas, while rockstar_dm/ implies that Rockstar halo finding ran using only dark-matter particles, which can produce more stable behavior.) By default, this HaloAnalysis package assumes that the raw text files that Rockstar produces have been converted to hdf5 format files that are in halo/rockstar_dm/catalog_hdf5/.\n",
    "\n",
    "Currently we run Rockstar halo finder using only dark-matter particles. This means that all halo quantities are computed using **only** dark-matter particles. Within halo/rockstar_dm/catalog_hdf5/, halo_*.hdf5 (one file per snapshot) and tree.hdf5 (one file across all snapshots) thus contain halo information based only on dark-matter particles.\n",
    "\n",
    "HaloAnalysis can assign baryonic (star or gas) particles to dark-matter halos in post-processing. By default, HaloAnalysis stores these properties for stars in files named catalog_hdf5/star_*.hdf5, with 1 file per snapshot. By default, the HaloAnalysis reader looks for these star files, and if they exist, it assigns those properties to the halo catalogs or trees when you read them. You can disable this, to read only dark-matter halo properties for speed/efficiency, by setting species=None in read_catalogs() or read_tree().\n",
    "\n",
    "Ensure that the halo_analysis and utilities directories are in your python path, then..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import halo_analysis as halo\n",
    "import utilities as ut\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can access the individual files/modules as named or use the aliases in __init__.py for convenience/brevity. for example, these are the same:\n",
    "\n",
    "halo.halo_io\n",
    "halo.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read halo catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we recommend that you copy this jupyter notebook tutorial into a simulation directory \n",
    "# (for example, m12i_res7100/) and run from there.\n",
    "# however, you can set simulation_directory below to point to any simulation directory and then run this notebook from anywhere\n",
    "\n",
    "# use this is you are running from within a simulation directory\n",
    "#simulation_directory = '.'\n",
    "\n",
    "# use this to point to a specific simulation directory, if you run this notebook from somwhere else\n",
    "simulation_directory = '/Users/awetzel/work/research/simulation/gizmo/simulations/m12/m12i/m12i_res7100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read a halo catalog at single snapshot (z = 0)\n",
    "\n",
    "hal = halo.io.IO.read_catalogs('redshift', 0, simulation_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hal is a dictionary of halo properties\n",
    "\n",
    "for k in hal.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# read halo catalogs at all available snapshots by supplying None or 'all' as the input snapshot value.\n",
    "# read_catalogs() returns this as a list of dictionaries, with the list index being the snapshot index.\n",
    "# beware - this can take a while to read...\n",
    "\n",
    "hals = halo.io.IO.read_catalogs('redshift', None, simulation_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# halo catalog at z = 0 (snapshot 600)\n",
    "hal_z0 = hals[600]\n",
    "\n",
    "# halo catalog at z = 1 (snapshot 277)\n",
    "hal_z1 = hals[277]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# else, you can read just a few specific snapshots\n",
    "# by default, it stores them in a (mostly emply) list, so the halo catalog list index = snapshot index\n",
    "\n",
    "hals = halo.io.IO.read_catalogs('redshift', [0, 1], simulation_directory)\n",
    "\n",
    "# halo catalog at z = 0 (snapshot 600)\n",
    "hal_z0 = hals[600]\n",
    "\n",
    "# halo catalog at z = 1 (snapshot 277)\n",
    "hal_z1 = hals[277]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternately, if you want a compact list (so halo catalog list index != snapshot index)\n",
    "\n",
    "hals = halo.io.IO.read_catalogs('redshift', [0, 1], simulation_directory, all_snapshot_list=False)\n",
    "\n",
    "hal_z1 = hals[0]\n",
    "hal_z0 = hals[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# halo properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read halo catalog at z = 0\n",
    "\n",
    "hal = halo.io.IO.read_catalogs('redshift', 0, simulation_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hal is a dictionary of halo properties\n",
    "\n",
    "for k in hal.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-D position (particle_number x dimension_number array) [kpc comoving]\n",
    "\n",
    "hal['position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-D velocity (particle_number x dimension_number array) [km/s physical]\n",
    "\n",
    "hal['velocity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DM mass of halo [M_sun]\n",
    "# by default, I run the halo finder using 200m (200 x the mean matter density) for the default overdensity/virial definition\n",
    "\n",
    "hal['mass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but Rockstar also stores halo DM mass based on different virial definitions [M_sun]\n",
    "\n",
    "print('{}\\n{}\\n{}'.format(hal['mass.200m'], hal['mass.vir'], hal['mass.200c']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DM mass that is bound to halo [M_sun]\n",
    "\n",
    "hal['mass.bound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# halo radius [kpc physical] again using 200m for the overdensity/virial definition \n",
    "\n",
    "hal['radius']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFW scale radius [kpc physical]\n",
    "\n",
    "hal['scale.radius']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum of the circular velocity profile [km/s physical]\n",
    "\n",
    "hal['vel.circ.max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation of the velocity (velocity dispersion) [km/s physical]\n",
    "\n",
    "hal['vel.std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the fraction of DM mass within R_200m that is low-resolution DM\n",
    "# this is a derived quantity, so you need to call via the .prop() function (see below)\n",
    "\n",
    "hal.prop('lowres.mass.frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of the primary (most massive) host halo in the catalog\n",
    "\n",
    "hal['host.index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-D distance to the primary host halo [kpc physical]\n",
    "\n",
    "hal['host.distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total (scalar) distance to the primary host halo [kpc physical]\n",
    "# this is a derived quantity, so you need to call via the .prop() function (see below)\n",
    "\n",
    "hal.prop('host.distance.total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-D velocity wrt the primary host halo [kpc physical]\n",
    "# radial and tangential velocity wrt the primary host halo [kpc physical]\n",
    "\n",
    "print(hal['host.velocity'])\n",
    "print(hal['host.velocity.rad'])\n",
    "print(hal['host.velocity.tan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .prop() to compute derived quantities\n",
    "# this can handle simple arithmetic conversions, such as the log of the mass, or the ratio of masses\n",
    "# see halo.io.HaloDictionaryClass for all options for derived quantities\n",
    "\n",
    "print(hal.prop('host.distance.total'))\n",
    "print(hal.prop('host.velocity.total'))\n",
    "print(hal.prop('log mass'))\n",
    "print(hal.prop('mass.bound / mass'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# halo catalogs with baryonic particle properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HaloAnalysis can assign baryonic (star or gas) particle properties to dark-matter halos in post-processing after generating the dark-matter halo catalogs. This package stores these baryonic properties in separate files, such as star_600.hdf5 for star particles at snapshot 600.\n",
    "\n",
    "By default, the HaloAnalysis reader automatically looks if star files exist at a snapshot that you read, and it will read and append these star properties to the halo catalog. You can disable this if you want to read only dark-matter halo properties for speed/efficiency, by setting species=None in read_catalogs()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicit input to ensure that it reads star particle properties for each halo\n",
    "\n",
    "hal = halo.io.IO.read_catalogs('redshift', 0, simulation_directory, species='star')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all stellar properties have dictionary keys as 'star.*'\n",
    "# list of star particle properties\n",
    "for k in hal:\n",
    "    if 'star.' in k:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find halos with star particles\n",
    "\n",
    "hindices = np.where(hal['star.mass'] > 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass of all star particles in halo [M_sun]\n",
    "\n",
    "hal['star.mass'][hindices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of star particles in halo [M_sun]\n",
    "\n",
    "hal['star.number'][hindices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radius that encloses 50%, 90% of the stellar mass [kpc physical]\n",
    "\n",
    "print(hal['star.radius.50'][hindices])\n",
    "print(hal['star.radius.90'][hindices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derived property: stellar density (within R_50) as a derived property [M_sun / kpc^3]\n",
    "\n",
    "hal.prop('star.density.50', hindices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stellar velocity dispersion (standard deviation) at R_50 [km / s]\n",
    "\n",
    "hal['star.vel.std.50'][hindices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center-of-mass position and velocity of star particles [kpc comoving]\n",
    "\n",
    "print(hal['star.position'][hindices])\n",
    "print(hal['star.velocity'][hindices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time (age of Universe) when galaxy formed 50%, 90%, etc of its current stellar mass [Gyr]\n",
    "\n",
    "print(hal['star.form.time.50'][hindices])\n",
    "print(hal['star.form.time.90'][hindices])\n",
    "print(hal['star.form.time.95'][hindices])\n",
    "print(hal['star.form.time.100'][hindices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert this to lookback-time via a derived property [Gyr]\n",
    "\n",
    "hal.prop('star.form.time.lookback.50', hindices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices of member star particles\n",
    "# for example, star particles assigned to halo 0 would be part_indices = hal['star.indies'][0]\n",
    "# then if you read in the star particles in the snapshot file, you can access member star particles via \n",
    "# part['star'][property_name][part_indices]\n",
    "\n",
    "hal['star.indices'][hindices[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are reading halos at some snapshot at z > 0, and if the GizmoAnalysis package already generated baryonic particle pointers for tracking baryonic particles between any snapshot at z > 0 and the snapshot at z = 0, you additionally can store the pointer indices from member baryonic particles in each halo at z > 0 to the particle catalog at z = 0 by setting assign_species_pointers=True as follows.\n",
    "\n",
    "There are no pointers at the snapshot at z = 0, becuase it would point to itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hal = halo.io.IO.read_catalogs('redshift', 1, simulation_directory, species='star', assign_species_pointers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindices = np.where(hal['star.mass'] > 0)[0]\n",
    "\n",
    "# indices of member star particles in the particle catalog at this snapshot\n",
    "print(hal['star.indices'][hindices[3]])\n",
    "\n",
    "# indices of member star particles in the particle catalog at the final snapshot at z = 0\n",
    "# in other words, where these member star particles end up in the particle array at z = 0\n",
    "print(hal['star.z0.indices'][hindices[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# additional information stored in sub-dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of useful information about the simulation\n",
    "\n",
    "hal.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary class of information about the cosmology of the simulation\n",
    "\n",
    "hal.Cosmology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of information about this snapshot's index, scale-factor, redshift, time, lookback-time\n",
    "\n",
    "hal.snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of arrays about *all* snapshots of the simulation\n",
    "\n",
    "print(hal.Snapshot.keys())\n",
    "print(hal.Snapshot['redshift'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# halo merger trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The halo finder treats each snapshot as an independent catalog, so halos at different snapshots do not know about each other. ConsistentTrees produces halo merger trees that link halos over time.\n",
    "\n",
    "ConsistentTrees applies some smoothing and physical consistency checks on halos over time, which leads to two important differences from the halo catalog: (1) not every halo in the catalog exists in the merger tree (especially those that are only marginally resolved) (2) some halos in the merger tree are 'phantom' halos that have been interpolated across snapshots but do not exist in the halo catalog at that snapshot.\n",
    "\n",
    "As with the halo catalogs, the HaloAnalysis reader can check for files that contain baryonic (star or gas) particle properies at each snapshot, and it can read and append these baryonic properties to the halo merger trees. Unlike reading a halo catalog at a single snapshot, HaloAnalysis disables this feature by default when reading the merger trees, because it requires reading in about 600 hdf5 files and thus can be slow. To enable it, set species='star' in read_tree()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read halo merger trees across all snapshots\n",
    "# this is a concatenated array of all halos across all snaphots, with pointers to progenitor and descendant halos\n",
    "\n",
    "halt = halo.io.IO.read_tree(simulation_directory=simulation_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# read halo merger trees across all snapshots and read member star particle files at each snapshot\n",
    "# this may take a while...\n",
    "\n",
    "halt = halo.io.IO.read_tree(simulation_directory=simulation_directory, species='star')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you only want to read star particle information at one or a few snapshots, you can specify which ones, which significantly speeds up the read time!\n",
    "# for example, read star particles information only at snapshot 277 (z = 1) and 600 (z = 0)\n",
    "\n",
    "halt = halo.io.IO.read_tree(simulation_directory=simulation_directory, species='star', species_snapshot_indices=[277, 600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read halo merger trees across all snapshots and read member star particles and pointer files at select snapshots\n",
    "\n",
    "halt = halo.io.IO.read_tree(simulation_directory=simulation_directory, species='star', species_snapshot_indices=[277, 600], assign_species_pointers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# halt is a dictionary of halo merger tree properties\n",
    "\n",
    "for k in halt.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each halo has its snapshot index (remember that the tree contains all halos at every snapshot)\n",
    "\n",
    "halt['snapshot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all halos at snapshot 600 (z = 0) and print their masses\n",
    "\n",
    "hindices = np.where(halt['snapshot'] == 600)[0]\n",
    "print(halt['mass'][hindices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices of member star particles at snapshot 277 and pointers tot their indices at z = 0 (snapshot 600)\n",
    "hindices = np.where(halt['star.mass'] > 0)[0]\n",
    "hindices = ut.array.get_indices(halt['snapshot'], 277, hindices)\n",
    "hindex = hindices[10]\n",
    "\n",
    "print(halt['star.indices'][hindex])\n",
    "print(halt['star.z0.indices'][hindex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternately, get catalog of halos only at snapshot 600 from tree\n",
    "\n",
    "hal = halo.io.IO.get_catalog_from_tree(halt, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag of whether halo is 'phantom' interpolation across snapshots\n",
    "\n",
    "halt['am.phantom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the tree index of a halo's descendant at a later (usually the next) snapshot\n",
    "# a negative value means that a halo does not have a descendant\n",
    "# ConsistentTrees allows only one descendant per halo\n",
    "\n",
    "print(halt['descendant.index'])\n",
    "\n",
    "# for example, get descendant of halo index 100 and print its mass\n",
    "hindex = 100\n",
    "desc_index = halt['descendant.index'][hindex]\n",
    "print(desc_index, halt['mass'][desc_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of progenitor halos (can be arbitrarily large) at an earler (usually the previous) snapshot\n",
    "# a negative value means that a halo does not have a progenitor\n",
    "\n",
    "halt['progenitor.number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree index of main (most massive) progenitor\n",
    "# loop over this to get list of main progenitors going back in time\n",
    "\n",
    "halt['progenitor.main.index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether I am the main (most massive) progenitor of my descendant\n",
    "\n",
    "halt['am.progenitor.main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree index of next co-progenitor\n",
    "\n",
    "halt['progenitor.co.index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree index of my descendant at the final snapshot (z = 0)\n",
    "\n",
    "halt['final.index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of walking the merger tree\n",
    "# find all progenitors and list their masses\n",
    "\n",
    "# start with a halo with tree index 0 (at z = 0)\n",
    "hindex = 0\n",
    "print(halt['snapshot'][hindex])\n",
    "print(halt['mass'][hindex])\n",
    "\n",
    "# find its progenitors, list their mass\n",
    "prog_index = halt['progenitor.main.index'][hindex]\n",
    "prog_indices = []\n",
    "while prog_index >= 0:\n",
    "    prog_indices.append(prog_index)\n",
    "    prog_index = halt['progenitor.co.index'][prog_index]\n",
    "print(prog_indices)\n",
    "print(halt['mass'][prog_indices])\n",
    "\n",
    "# for the main progenitor, find its progenitors, list their mass\n",
    "hindex = prog_indices[0]\n",
    "prog_index = halt['progenitor.main.index'][hindex]\n",
    "prog_indices = []\n",
    "while prog_index >= 0:\n",
    "    prog_indices.append(prog_index)\n",
    "    prog_index = halt['progenitor.co.index'][prog_index]\n",
    "print(prog_indices)\n",
    "print(halt['mass'][prog_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of walking the merger tree\n",
    "# get list of main progenitors as far back as can go\n",
    "\n",
    "hindex = 0\n",
    "prog_main_index = hindex\n",
    "prog_main_indices = []\n",
    "while prog_main_index >= 0:\n",
    "    prog_main_indices.append(prog_main_index)\n",
    "    prog_main_index = halt['progenitor.main.index'][prog_main_index]\n",
    "\n",
    "print(prog_main_indices)\n",
    "print(halt['mass'][prog_main_indices])\n",
    "print(halt['position'][prog_main_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# halt.prop() computes derived quantities and can make walking the halo merger tree much easier\n",
    "\n",
    "# for halo with tree index = 0, get its main progenitors going back as far as can (including self)\n",
    "hindex = 0\n",
    "prog_indices = halt.prop('progenitor.main.indices', hindex)\n",
    "\n",
    "# print mass history\n",
    "print(prog_indices)\n",
    "print(halt['mass'][prog_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print stellar mass history - recall that not all snapshots necessarily have star particle information\n",
    "\n",
    "print(halt['star.mass'][prog_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can do this for an array of halo indices as well\n",
    "# it will return progenitor indices as 2-D array (halo number x progenitor number) with null values \n",
    "# (snapshot before a halo existed) as (safely) negative\n",
    "\n",
    "hindices = np.where(halt['snapshot'] == 600)[0]\n",
    "prog_indices = halt.prop('progenitor.main.indices', hindices)\n",
    "print(prog_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for descendant halos (going forward in time as far as can)\n",
    "\n",
    "hindices = np.where(halt['snapshot'] == 100)[0]\n",
    "desc_indices = halt.prop('descendant.indices', hindices)\n",
    "print(desc_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternately, get *all* of the progenitors at previous snapshot and print their masses\n",
    "\n",
    "hindex = 2\n",
    "prog_indices = halt.prop('progenitor.indices', hindex)\n",
    "\n",
    "print(prog_indices)\n",
    "print(halt['mass'][prog_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this also works with an input list (array) of halos\n",
    "# but now it returns a list of progenitor index arrays\n",
    "# because each halo has a variable (and potentially unlimited) number of progenitors\n",
    "\n",
    "hindices = np.where(halt['snapshot'] == 100)[0]\n",
    "hindices = hindices[:10]\n",
    "prog_indices = halt.prop('progenitor.indices', hindices)\n",
    "\n",
    "print(prog_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the halo catalogs contains history-based properties of each halo, such as peak mass or peak circular velocity\n",
    "# you can use .prop() to compute these on the fly within the merger trees for any property\n",
    "# you can get either the full history for that property or the peak (maximum) value\n",
    "# again, you can do this for a single halo or an array of them\n",
    "\n",
    "hindices = np.where(halt['snapshot'] == 600)[0]\n",
    "\n",
    "# one halo\n",
    "hindex = hindices[0]\n",
    "print(halt.prop('mass.bound.history', hindex))\n",
    "print(halt.prop('mass.bound.peak', hindex))\n",
    "\n",
    "# array of halos\n",
    "print(halt.prop('mass.bound.history', hindices))\n",
    "print(halt.prop('mass.bound.peak', hindices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interfacting between halo catalog and merger trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each halo in the merger tree has a pointer to its array index in the halo catalog: 'catalog.index'\n",
    "\n",
    "Conversely, each halo in the catalog has a pointer to its array index in the merger tree: 'tree.index'\n",
    "\n",
    "You can use these to go back and forth between the two.\n",
    "\n",
    "Note: halo merger tree ids/indices are unique across all snapshots, but halo catalog ids/indices are unique only at a given snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read halo merger trees across all snapshots\n",
    "halt = halo.io.IO.read_tree(simulation_directory=simulation_directory)\n",
    "\n",
    "# read halo catalog at a snapshot\n",
    "hal = halo.io.IO.read_catalogs('redshift', 2, simulation_directory=simulation_directory, species=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index of the halo in the merger trees\n",
    "cat_index = 100  # some halo of interest\n",
    "print(hal['mass'][cat_index])\n",
    "tree_index = hal['tree.index'][cat_index]\n",
    "print(tree_index)\n",
    "print(halt['mass'][tree_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversely, starting from the halo merger tree, get index of the halo in the catalog\n",
    "# because halo catalog indices are *not* unique across snapshots,\n",
    "# you also need to use which snapshot index the halo points to\n",
    "\n",
    "hindices = np.where(halt['snapshot'] == 172)[0]\n",
    "tree_index = hindices[0]  # some halo of interest\n",
    "print(halt['mass'][tree_index])\n",
    "snapshot_index = halt['snapshot'][tree_index]  # index of snapshot in halo catalog\n",
    "cat_index = halt['catalog.index'][tree_index]  # halo catalog index at snapshot\n",
    "print(snapshot_index, cat_index)\n",
    "print(hal['mass'][cat_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See halo.plot for examples of analyzing/plotting halos in the catalog and merger trees.\n",
    "\n",
    "See utilities package for lower-level functions that may be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "563616ea0795551886fedfb6f43611ed89f67b819df42e5edfc6c6ce5ab0ec12"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
